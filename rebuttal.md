
Reviewer: 1
===========

_This perspective paper proposes that we change the language we use to report significance of hypothesis tests. They suggest that a simple change in the language will help clarify the meaning and also help highlight the importance of effect sizes and confidence intervals. Overall, it’s well-written and is a good contribution to this important subject area. We should be open to ideas that experiment and potentially improve how we use NHST._

_I agree that a downside of hypothesis testing is often (wrongly) seen as an end in itself, rather than the scientific knowledge that is gained from the test. However, I am not convinced that your suggestion will solve this. Here are my thoughts:_

Thanks for your perspective. We are also not convinced our suggestion will solve this major problem, to put it mildly. But we hope it will help (and think that in small ways it already has). We respond to your specific points below.

_2. I don’t understand the logic that using the term ‘clear’ automatically makes the need for effect sizes and confidence intervals more obvious. Can you explain this logical jump more fully within the manuscript?_

We don't argue that it's automatic, but we do rely on the assumption that use of a term whose colloquial meaning closely matches what P values indicate will lead to clearer communication. We gave an example where we believe the word "clear" underlines the absence of effect sizes (L136 of ORIGINAL), and mentioned CIs in the table. We have now added another mention to the table, and an UNCONVINCING comment to the ¶ where we present the table.

_3. If some people adopt this terminology, whilst others do not, it could become a very confusing and unclear landscape of scientific understanding. I think this would have more strength if a single domain or several journals gave new guidelines to only use this term, however that would likely require a more evidence-based case than presented here._

We agree about strength, and hope to head in this direction. Publishing the idea is, we hope, a first step. We have found through informal discussion that there is little confusion when the idea of clarity is combined with reference to P values or confidence intervals. We have made this point more explicit in the MS. 

_4. The philosophy of NHST is so deeply embedded within science, it seems unlikely that changing the terminology will change how people use or interpret NHST. For example ‘significance’ has a technical and objective meaning. ‘clear’ is a simpler word that is also more subjective. Using ‘clear’ may allow “significant” to reclaim its common definition, but perhaps ‘clear’ would then become a term that has a specific and altered meaning within scientific manuscripts, with all the same drawbacks that ‘significance’ now has. i.e. maybe the benefits would be short-lived until we are familiar with the new term._

Maybe. Both words have subjective meanings, and either word can be vested with a technical statistical meaning. Our larger point is that the technical statistical meaning has more in common with the informal meanings of "clear" than "significant".

_In some of the examples in your table, the sentences on the right are better, but that seems to be unconnected to the use ‘clear’. In 5th example, your phrasing is much improved, but seems that the word ‘clear’ could be replaced with ‘significant’ for the same effect. So this table seems to confound poor interpretation practice with the language used. I recognise that you claim the language will help the interpretation, but it’s difficult to judge that from these examples._

This is a good point, and also a tricky one. The bad wording is from the literature. We believe that confusion arising partially from the poor fit of the word "significant" to this application is leading to poor wording, but there is no easy way to de-confound. We have pointed this out more explicitly now. 

_Line 92 “promise to substantially improve statistical communication”. This is a bold and unsubstantiated claim!_

We have toned down the claim. 

Reviewer: 2
===========

_I really liked this piece! I have frequently been frustrated with the interpretation of p-values among my colleagues (and by myself, at different stages in the past) and so i welcome the clarity that you are trying to bring to this important point._

_As a brief summary of the paper's argument: the frequent misinterpretation of NHST is due to confusing language around the results of tests. The suggestion is that we switch to considering p-values as a measure of "clarity" : that is, how clearly an effect could be seen. This language is narrower by design: too narrow, in fact, to cover all the meanings we might want to extract from a statistical procedure. The hope then is that scientists would move on to describe exactly *what* was detected clearly: an effect size, a point estimate and confidence interval, etc._

_I was confused by the paragraph starting on Line 55. A "permutation-based t-test" is a very specific metaphor, and I don't think that readers will grasp the similarity to the p-values from, say, an ANOVA without a bit more signposting.  More generally, I expected this paragraph to summarize the "correct" interpretation of p-values, and perhaps to illustrate how and why they are used in scientific papers._

We have rewritten the paragraph to be more straightforward.

_My major concern from the beginning of this manuscript is actually mentioned by the authors themselves towards the end: the so-called "Winner's Curse". This is the idea, articulated by Andrew Gelman among others, that if an effect is "significant" it is also likely to be an overestimate. In low-powered studies, the estimated effect size can even be opposite in direction to the true effect, yet the p-value is still a low number.  Many ecologists (in my experience) believe that a low p-value indicates two things at the same time: first, that the study "worked"; second, that the effect is real. Neither is necessarily true, and neither can be reliably inferred from the p-value alone. I'm sure the authors are aware of these points, and i think it would be useful to expand on them a bit more. In brief, while I really like the idea of "seeing with clarity", i would appreciate some discussion of how to tell if one has clearly seen a mere mirage._

This is an important concern. We have expanded our discussion of this point, while trying not to stray too far from our main focus. 

_I really enjoyed this manuscript and i think ecologists need to read it. I don't want to be negative, but I can't resist a skeptical question: is there any evidence that people will change their behaviours? Misinterpretation of p-values is but one of the many statistical and philosophical errors that pervade science. These will persist until incentive structures change. Until they do, people will continue to abuse their data, their analyses, and their interpretations._

Thanks for your kind words. We agree that this article cannot by itself overcome deeply embedded bad practice, but we hope it will be part of a larger change in a good direction.
